# Update all mirrored repos to sync with their upstream repositories (Parallelized)
name: Update Mirrors

on:
  push:
    paths:
      - .github/workflows/update-mirrors.yml
      - .github/workflows/update-mirrors.ps1
      - .github/workflows/update-mirrors-chunk.ps1
      - .github/workflows/library.ps1

  schedule:
   # run every hour, as a run takes around 30 mins now
    - cron: '12 */1 * * *'

  workflow_dispatch:
    inputs:
      numberOfRepos:
        description: 'Number of repos to update (default: 300)'
        required: false
        default: '300'
      numberOfChunks:
        description: 'Number of parallel chunks (default: 4)'
        required: false
        default: '4'

env:
  numberOfReposToDo: 300
  numberOfChunks: 4
  APP_ID: ${{ vars.APPLICATION_ID }}
  APP_ID_2: ${{ vars.APPLICATION_ID_2 }}
  APP_ID_3: ${{ vars.APPLICATION_ID_3 }}
  APP_ORGANIZATION: actions-marketplace-validations

jobs:
  prepare:
    name: Prepare work distribution
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      matrix: ${{ steps.split-work.outputs.matrix }}
      chunks: ${{ steps.split-work.outputs.chunks }}
    steps:
      - uses: actions/checkout@v6

      - name: Download status.json from blob storage
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Get-StatusFromBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Error "Failed to download status.json from blob storage"
            exit 1
          }

      - name: Split work into chunks
        id: split-work
        shell: pwsh
        run: |
          . ./.github/workflows/library.ps1

          Write-Message -message "# Work Distribution for Parallel Processing" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          try {
              # Clean BOM if present before parsing JSON
              $jsonContent = Get-Content status.json -Raw
              $jsonContent = $jsonContent -replace '^\uFEFF', ''  # Remove UTF-8 BOM (Unicode)
              $existingForks = $jsonContent | ConvertFrom-Json
          } catch {
              Write-Host "=== STATUS.JSON PARSE ERROR ==="
              Write-Host "JSON parsing failed: $($_.Exception.Message)"
              Write-Host "First 10 lines of status.json:"
              Get-Content status.json | Select-Object -First 10 | ForEach-Object { Write-Host $_ }
              exit 1
          }

          Write-Message -message "Found [$($existingForks.Length)] total mirrors in the status file" -logToSummary $true

          # Use workflow inputs if available, otherwise use env variables
          $numberOfRepos = [int]("${{ github.event.inputs.numberOfRepos }}" -ne "" ? "${{ github.event.inputs.numberOfRepos }}" : "${{ env.numberOfReposToDo }}")
          $numberOfChunks = [int]("${{ github.event.inputs.numberOfChunks }}" -ne "" ? "${{ github.event.inputs.numberOfChunks }}" : "${{ env.numberOfChunks }}")

          Write-Message -message "Configuration: Process up to [$numberOfRepos] repos using [$numberOfChunks] parallel jobs" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          # Select forks to process with prioritization based on last sync time
          # This ensures we don't keep retrying the same repos over and over
          $forksToProcess = Select-ForksToProcess -existingForks $existingForks -numberOfRepos $numberOfRepos -coolOffHoursForFailedSync 24

          # Split the work
          $chunks = Split-ForksIntoChunks -existingForks $forksToProcess -numberOfChunks $numberOfChunks

          # Create matrix configuration
          $matrixIds = @()
          foreach ($chunkId in $chunks.Keys) {
              $matrixIds += $chunkId
          }

          # Sort to ensure consistent order
          $matrixIds = $matrixIds | Sort-Object

          # Save chunks to files for each matrix job to pick up
          foreach ($chunkId in $matrixIds) {
              $chunkFile = "chunk-$chunkId.json"
              $chunks[$chunkId] | ConvertTo-Json -Compress | Out-File $chunkFile -Encoding UTF8
              Write-Host "Saved chunk [$chunkId] to [$chunkFile] with [$($chunks[$chunkId].Count)] forks"
          }

          # Output matrix configuration
          $matrixJson = ConvertTo-Json -InputObject $matrixIds -Compress
          Write-Host "Matrix configuration: $matrixJson"

          # Set outputs for next job
          "matrix=$matrixJson" >> $env:GITHUB_OUTPUT
          "chunks=$($matrixIds.Count)" >> $env:GITHUB_OUTPUT

          Write-Message -message "" -logToSummary $true
          Write-Message -message "‚úì Work distribution complete. Starting [$(DisplayIntWithDots $matrixIds.Count)] parallel jobs." -logToSummary $true

      - name: Upload chunk files
        uses: actions/upload-artifact@v6
        with:
          name: work-chunks
          path: chunk-*.json
          retention-days: 1

  update-mirrors:
    name: Update mirrors (chunk ${{ matrix.chunk-id }})
    needs: prepare
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        chunk-id: ${{ fromJson(needs.prepare.outputs.matrix) }}
    permissions:
      actions: read
    steps:
      - uses: actions/checkout@v6

      - name: Download status.json from blob storage
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Get-StatusFromBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Error "Failed to download status.json from blob storage"
            exit 1
          }

      - name: Download work chunks
        uses: actions/download-artifact@v7
        with:
          name: work-chunks
          path: .

      - name: Process chunk ${{ matrix.chunk-id }}
        shell: pwsh
        env:
          APPLICATION_PRIVATE_KEY: ${{ secrets.AUTOMATION_APP_KEY }}
          APPLICATION_PRIVATE_KEY_2: ${{ secrets.AUTOMATION_APP_KEY2 }}
          APPLICATION_PRIVATE_KEY_3: ${{ secrets.AUTOMATION_APP_KEY3 }}
        run: |
          . ./.github/workflows/library.ps1

          $chunkId = ${{ matrix.chunk-id }}
          Write-Message -message "# Processing Chunk [$chunkId]" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          # Load status
          try {
              $jsonContent = Get-Content status.json -Raw
              $jsonContent = $jsonContent -replace '^\uFEFF', ''
              $existingForks = $jsonContent | ConvertFrom-Json
          } catch {
              Write-Error "Failed to parse status.json: $($_.Exception.Message)"
              exit 1
          }

          # Load chunk work
          $chunkFile = "chunk-$chunkId.json"
          if (-not (Test-Path $chunkFile)) {
              Write-Error "Chunk file not found: $chunkFile"
              exit 1
          }

          $forkNames = Get-Content $chunkFile | ConvertFrom-Json
          Write-Message -message "Loaded [$(DisplayIntWithDots $forkNames.Count)] forks to process from [$chunkFile]" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          # Process the chunk
          ./.github/workflows/update-mirrors-chunk.ps1 `
            -actions $existingForks `
            -forkNames $forkNames `
            -chunkId $chunkId

      - name: Upload partial status for chunk ${{ matrix.chunk-id }}
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: status-partial-${{ matrix.chunk-id }}
          path: status-partial-${{ matrix.chunk-id }}.json
          retention-days: 1
          if-no-files-found: warn

      - name: Upload chunk summary for chunk ${{ matrix.chunk-id }}
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: chunk-summary-${{ matrix.chunk-id }}
          path: chunk-summary-${{ matrix.chunk-id }}.json
          retention-days: 1
          if-no-files-found: warn

  consolidate:
    name: Consolidate results and update storage
    needs: [prepare, update-mirrors]
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 15
    concurrency:
      group: repo-state-updates
      cancel-in-progress: false
    steps:
      - uses: actions/checkout@v6

      - name: Download status.json from blob storage
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Get-StatusFromBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Error "Failed to download status.json from blob storage"
            exit 1
          }

      - name: Download failedForks.json from blob storage
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Get-FailedForksFromBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Error "Failed to download failedForks.json from blob storage"
            exit 1
          }

      - name: Download all partial status updates
        uses: actions/download-artifact@v7
        with:
          pattern: status-partial-*
          path: partial-updates/
          merge-multiple: true

      - name: Download all chunk summaries
        uses: actions/download-artifact@v7
        with:
          pattern: chunk-summary-*
          path: chunk-summaries/
          merge-multiple: true

      - name: Show consolidated chunk summary
        shell: pwsh
        run: |
          . ./.github/workflows/library.ps1

          # Find all chunk summary files
          $summaryFiles = Get-ChildItem -Path "chunk-summaries" -Filter "chunk-summary-*.json" -ErrorAction SilentlyContinue | Select-Object -ExpandProperty FullName
          
          if ($summaryFiles) {
            Write-Host "Found [$($summaryFiles.Count)] chunk summary files"
            Show-ConsolidatedChunkSummary -chunkSummaryFiles $summaryFiles
          } else {
            Write-Warning "No chunk summary files found"
          }

      - name: Merge partial updates and save
        shell: pwsh
        run: |
          . ./.github/workflows/library.ps1

          Write-Message -message "# Consolidating Results from All Chunks" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          # Load current status
          try {
              $jsonContent = Get-Content status.json -Raw
              $jsonContent = $jsonContent -replace '^\uFEFF', ''
              $currentStatus = $jsonContent | ConvertFrom-Json
          } catch {
              Write-Error "Failed to parse status.json: $($_.Exception.Message)"
              exit 1
          }

          Write-Message -message "Loaded current status with [$(DisplayIntWithDots $currentStatus.Count)] forks" -logToSummary $true

          # Find all partial status files
          $partialFiles = Get-ChildItem -Path "partial-updates" -Filter "status-partial-*.json" | Select-Object -ExpandProperty FullName
          Write-Message -message "Found [$(DisplayIntWithDots $partialFiles.Count)] partial status files to merge" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          # Merge all partial updates
          $mergedStatus = Merge-PartialStatusUpdates -currentStatus $currentStatus -partialStatusFiles $partialFiles

          # Save merged status
          Write-Message -message "Saving merged status with [$(DisplayIntWithDots $mergedStatus.Count)] forks" -logToSummary $true
          SaveStatus -existingForks $mergedStatus

          Write-Message -message "" -logToSummary $true
          Write-Message -message "‚úì Consolidation complete" -logToSummary $true

      - name: Show overall statistics
        shell: pwsh
        run: |
          . ./.github/workflows/library.ps1

          # Load the merged status
          $jsonContent = Get-Content status.json -Raw
          $jsonContent = $jsonContent -replace '^\uFEFF', ''
          $existingForks = $jsonContent | ConvertFrom-Json

          ShowOverallDatasetStatistics -existingForks $existingForks

      - name: Check rate limit status
        shell: pwsh
        env:
          APPLICATION_PRIVATE_KEY: ${{ secrets.AUTOMATION_APP_KEY }}
          APPLICATION_PRIVATE_KEY_2: ${{ secrets.AUTOMATION_APP_KEY2 }}
          APPLICATION_PRIVATE_KEY_3: ${{ secrets.AUTOMATION_APP_KEY3 }}
        run: |
          . ./.github/workflows/library.ps1

          Invoke-GitHubAppRateLimitCheckForConfiguredApps

      - name: Setup Node.js for API updates
        uses: actions/setup-node@v6
        with:
          node-version: '20'
          registry-url: 'https://npm.pkg.github.com'
          scope: '@devops-actions'

      - name: Install npm package for API updates
        env:
          NODE_AUTH_TOKEN: ${{ secrets.DEVOPS_ACTIONS_PACKAGE_DOWNLOAD }}
        run: |
          npm install @devops-actions/actions-marketplace-client

      - name: Update API storage with consolidated data
        if: always()
        shell: pwsh
        env:
          AZ_FUNCTION_URL: ${{ vars.AZ_FUNCTION_URL }}
          AZ_FUNCTION_TOKEN: ${{ secrets.AZ_FUNCTION_TOKEN }}
        run: |
          . ./.github/workflows/library.ps1

          Write-Message -message "" -logToSummary $true
          Write-Message -message "## API Storage Update" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          # Check if API credentials are available
          if ([string]::IsNullOrWhiteSpace($env:AZ_FUNCTION_URL) -or [string]::IsNullOrWhiteSpace($env:AZ_FUNCTION_TOKEN)) {
            Write-Message -message "‚ö†Ô∏è API credentials not available - skipping API update" -logToSummary $true
            exit 0
          }

          # Load the merged status
          try {
            $jsonContent = Get-Content status.json -Raw
            $jsonContent = $jsonContent -replace '^\uFEFF', ''
            $status = $jsonContent | ConvertFrom-Json
          } catch {
            Write-Message -message "‚ùå Failed to load status.json: $($_.Exception.Message)" -logToSummary $true
            exit 0
          }

          Write-Host "Uploading up to 100 actions to API storage..."

          # Call the API upsert function
          $numberOfRepos = 100
          $result = Invoke-ApiUpsert -status $status -apiUrl $env:AZ_FUNCTION_URL -functionKey $env:AZ_FUNCTION_TOKEN -numberOfRepos $numberOfRepos

          # Report results in step summary
          if ($result.error) {
            Write-Message -message "‚ö†Ô∏è API update encountered an error: $($result.error)" -logToSummary $true
          } else {
            $totalUpdates = $result.createdCount + $result.updatedCount
            Write-Message -message "| Status | Count |" -logToSummary $true
            Write-Message -message "|--------|------:|" -logToSummary $true
            Write-Message -message "| ‚úÖ Successful | $($result.successCount) |" -logToSummary $true
            Write-Message -message "| ‚ùå Failed | $($result.failCount) |" -logToSummary $true
            Write-Message -message "| üÜï Created | $($result.createdCount) |" -logToSummary $true
            Write-Message -message "| üìù Updated | $($result.updatedCount) |" -logToSummary $true
            Write-Message -message "| ‚è≠Ô∏è Skipped | $($result.skippedCount) |" -logToSummary $true
            Write-Message -message "" -logToSummary $true
            Write-Message -message "‚úì Total updates to API: **$totalUpdates** (created + updated)" -logToSummary $true
          }

          Write-Message -message "" -logToSummary $true

      - name: Upload status.json to blob storage
        if: always()
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Set-StatusToBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Warning "Failed to upload status.json to blob storage"
            # Don't exit 1 here - we want to continue to upload failedForks.json
          } else {
            Write-Host "Successfully uploaded status.json to blob storage"
          }

      - name: Upload failedForks.json to blob storage
        if: always()
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Set-FailedForksToBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Warning "Failed to upload failedForks.json to blob storage"
            # Don't exit 1 here - we still want the workflow to complete
          } else {
            Write-Host "Successfully uploaded failedForks.json to blob storage"
          }

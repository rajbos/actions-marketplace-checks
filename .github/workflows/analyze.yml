# Get repo data for mirrored actions (Parallelized)
# Get new data from Dependabot
# Store the data in Azure Blob Storage

name: Analyze

on:
  push:
    paths:
      - .github/workflows/analyze.yml
      - .github/workflows/functions.ps1
      - .github/workflows/functions-chunk.ps1
      - .github/workflows/repoInfo.ps1
      - .github/workflows/repoInfo-chunk.ps1

  schedule:
     #- cron: '*/60 * * * *'
     # Run at minute 5 to avoid overlap with Update Mirrors (minute 35) and Get repo info (minute 50)
     - cron: '5 */1 * * *'

  workflow_dispatch:
    inputs:
      numberOfReposRepoInfo:
        description: 'Number of repos for repo info (default: 150)'
        required: false
        default: '150'
      numberOfChunks:
        description: 'Number of parallel chunks (default: 10)'
        required: false
        default: '10'

# Prevent concurrent runs of this workflow to reduce rate limit pressure
concurrency:
  group: analyze-workflow
  cancel-in-progress: false
  
env:
  numberOfReposRepoInfo: 150
  # Reduced from 25 to 10 to decrease rate limit pressure when running concurrently with other workflows
  numberOfChunks: 10
  APP_ID: ${{ vars.APPLICATION_ID }}
  APP_ID_2: ${{ vars.APPLICATION_ID_2 }}
  APP_ID_3: ${{ vars.APPLICATION_ID_3 }}
  APP_ORGANIZATION: actions-marketplace-validations

jobs:
  prepare:
    name: Prepare work distribution
    runs-on: ubuntu-latest
    permissions:
      contents: read
    outputs:
      matrix-repoinfo: ${{ steps.split-work.outputs.matrix-repoinfo }}
    steps:
      - uses: actions/checkout@v6

      - name: Get current actions list
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Get-ActionsJsonFromBlobStorage -sasToken $env:BLOB_SAS_TOKEN -localFilePath "actions.json"
          if (-not $result) {
            Write-Error "Failed to download actions.json from blob storage"
            exit 1
          }
          
          # Show first 10 lines for debugging
          Write-Host ""
          Write-Host "Content of the file (first 10 lines):"
          Get-Content "actions.json" -TotalCount 10 | ForEach-Object { Write-Host $_ }

      - name: Download status.json from blob storage
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Get-StatusFromBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Error "Failed to download status.json from blob storage"
            exit 1
          }

      - name: Download failedForks.json from blob storage
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Get-FailedForksFromBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Error "Failed to download failedForks.json from blob storage"
            exit 1
          }

      - name: Split work into chunks
        id: split-work
        shell: pwsh
        run: |
          . ./.github/workflows/library.ps1

          Write-Message -message "# Work Distribution for Parallel Processing" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          try {
              # Clean BOM if present before parsing JSON
              $jsonContent = Get-Content actions.json -Raw
              $jsonContent = $jsonContent -replace '^\uFEFF', ''  # Remove UTF-8 BOM (Unicode)
              $actions = $jsonContent | ConvertFrom-Json
          } catch {
              Write-Host "=== ACTIONS.JSON PARSE ERROR ==="
              Write-Host "JSON parsing failed: $($_.Exception.Message)"
              Write-Host "First 10 lines of actions.json:"
              Get-Content actions.json | Select-Object -First 10 | ForEach-Object { Write-Host $_ }
              exit 1
          }

          Write-Message -message "Found [$($actions.Length)] total actions in the datafile" -logToSummary $true

          # Use workflow inputs if available, otherwise use env variables
          $numberOfReposRepoInfo = [int]("${{ github.event.inputs.numberOfReposRepoInfo }}" -ne "" ? "${{ github.event.inputs.numberOfReposRepoInfo }}" : "${{ env.numberOfReposRepoInfo }}")
          $numberOfChunks = [int]("${{ github.event.inputs.numberOfChunks }}" -ne "" ? "${{ github.event.inputs.numberOfChunks }}" : "${{ env.numberOfChunks }}")

          Write-Message -message "Configuration: RepoInfo up to [$numberOfReposRepoInfo] repos, using [$numberOfChunks] parallel jobs" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          # Load existing status
          try {
              $statusContent = Get-Content status.json -Raw
              $statusContent = $statusContent -replace '^\uFEFF', ''
              $existingForks = $statusContent | ConvertFrom-Json
          } catch {
              Write-Host "=== STATUS.JSON PARSE ERROR ==="
              Write-Host "JSON parsing failed: $($_.Exception.Message)"
              exit 1
          }

          # Limit existing forks for repo info
          $forksForRepoInfo = $existingForks | Where-Object { $_.forkFound -eq $true } | Select-Object -First $numberOfReposRepoInfo
          
            # Split the work for repo info
            $chunksRepoInfoRaw = Split-ForksIntoChunks -existingForks $forksForRepoInfo -numberOfChunks $numberOfChunks

            # Create matrix configuration
            $matrixIdsRepoInfo = @()
            foreach ($chunkId in $chunksRepoInfoRaw.Keys) {
              $matrixIdsRepoInfo += $chunkId
            }

            # Sort to ensure consistent order
            $matrixIdsRepoInfo = $matrixIdsRepoInfo | Sort-Object

            # Save chunks to files for each matrix job to pick up
            foreach ($chunkId in $matrixIdsRepoInfo) {
              $chunkFile = "chunk-repoinfo-$chunkId.json"
              $chunksRepoInfoRaw[$chunkId] | ConvertTo-Json -Compress | Out-File $chunkFile -Encoding UTF8
              Write-Host "Saved repoinfo chunk [$chunkId] to [$chunkFile] with [$($chunksRepoInfoRaw[$chunkId].Count)] forks"
            }

            # Output matrix configurations
            $matrixRepoInfoJson = ConvertTo-Json -InputObject $matrixIdsRepoInfo -Compress
            Write-Host "RepoInfo matrix configuration: $matrixRepoInfoJson"

            # Set outputs for next jobs
            "matrix-repoinfo=$matrixRepoInfoJson" >> $env:GITHUB_OUTPUT

          Write-Message -message "" -logToSummary $true
          Write-Message -message "‚úì Work distribution complete. Starting parallel jobs." -logToSummary $true

      - name: Upload chunk files
        uses: actions/upload-artifact@v6
        with:
          name: work-chunks
          path: chunk-*.json
          retention-days: 1

  repo-info:
    name: Get repo info (chunk ${{ matrix.chunk-id }})
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        chunk-id: ${{ fromJson(needs.prepare.outputs.matrix-repoinfo) }}
    permissions:
      actions: read
    steps:
      - uses: actions/checkout@v6

      - name: Download status.json from blob storage
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Get-StatusFromBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Error "Failed to download status.json from blob storage"
            exit 1
          }

      - name: Download actions.json from blob storage
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Get-ActionsJsonFromBlobStorage -sasToken $env:BLOB_SAS_TOKEN -localFilePath "actions.json"
          if (-not $result) {
            Write-Error "Failed to download actions.json from blob storage"
            exit 1
          }

      - name: Download work chunks
        uses: actions/download-artifact@v7
        with:
          name: work-chunks
          path: .

      - name: Install PowerShell modules
        shell: pwsh
        run: |
          Install-Module -name powershell-yaml -Force -Repository PSGallery -Scope CurrentUser -Allowclobber

      - name: Process repo info chunk ${{ matrix.chunk-id }}
        shell: pwsh
        env:
          APPLICATION_PRIVATE_KEY: ${{ secrets.AUTOMATION_APP_KEY }}
          APPLICATION_PRIVATE_KEY_2: ${{ secrets.AUTOMATION_APP_KEY2 }}
          APPLICATION_PRIVATE_KEY_3: ${{ secrets.AUTOMATION_APP_KEY3 }}
        run: |
          . ./.github/workflows/library.ps1

          $chunkId = ${{ matrix.chunk-id }}
          Write-Message -message "# Processing RepoInfo Chunk [$chunkId]" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          # Load actions
          try {
              $jsonContent = Get-Content actions.json -Raw
              $jsonContent = $jsonContent -replace '^\uFEFF', ''
              $actions = $jsonContent | ConvertFrom-Json
          } catch {
              Write-Error "Failed to parse actions.json: $($_.Exception.Message)"
              exit 1
          }

          # Load chunk work
          $chunkFile = "chunk-repoinfo-$chunkId.json"
          if (-not (Test-Path $chunkFile)) {
              Write-Error "Chunk file not found: $chunkFile"
              exit 1
          }

          $actionNames = Get-Content $chunkFile | ConvertFrom-Json
          Write-Message -message "Loaded [$(DisplayIntWithDots $actionNames.Count)] actions to process from [$chunkFile]" -logToSummary $true
          Write-Message -message "" -logToSummary $true
          # Process the chunk
          ./.github/workflows/repoInfo-chunk.ps1 `
            -actions $actions `
            -actionNames $actionNames `
            -chunkId $chunkId

      - name: Upload partial status for repo info chunk ${{ matrix.chunk-id }}
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: status-partial-repoinfo-${{ matrix.chunk-id }}
          path: status-partial-repoinfo-${{ matrix.chunk-id }}.json
          retention-days: 1
          if-no-files-found: warn

  consolidate:
    name: Consolidate results and update storage
    needs: [prepare, repo-info]
    if: always()
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read
    concurrency:
      group: repo-state-updates
      cancel-in-progress: false
    steps:
      - uses: actions/checkout@v6

      - name: Download status.json from blob storage
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Get-StatusFromBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Error "Failed to download status.json from blob storage"
            exit 1
          }

      - name: Download failedForks.json from blob storage
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Get-FailedForksFromBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Error "Failed to download failedForks.json from blob storage"
            exit 1
          }

      - name: Download all partial status updates
        uses: actions/download-artifact@v7
        with:
          pattern: status-partial-*
          path: partial-updates/
          merge-multiple: true

      - name: Merge partial updates and save
        shell: pwsh
        run: |
          . ./.github/workflows/library.ps1

          Write-Message -message "# Consolidating Results from All Chunks" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          # Load current status
          try {
              $jsonContent = Get-Content status.json -Raw
              $jsonContent = $jsonContent -replace '^\uFEFF', ''
              $currentStatus = $jsonContent | ConvertFrom-Json
          } catch {
              Write-Error "Failed to parse status.json: $($_.Exception.Message)"
              exit 1
          }

          Write-Message -message "Loaded current status with [$(DisplayIntWithDots $currentStatus.Count)] forks" -logToSummary $true

          # Find all partial status files
          $partialFiles = Get-ChildItem -Path "partial-updates" -Filter "status-partial-*.json" -ErrorAction SilentlyContinue | Select-Object -ExpandProperty FullName
          
          if ($partialFiles) {
              Write-Message -message "Found [$(DisplayIntWithDots $partialFiles.Count)] partial status files to merge" -logToSummary $true
              Write-Message -message "" -logToSummary $true

              # Merge all partial updates
              $mergedStatus = Merge-PartialStatusUpdates -currentStatus $currentStatus -partialStatusFiles $partialFiles

              # Save merged status
              Write-Message -message "Saving merged status with [$(DisplayIntWithDots $mergedStatus.Count)] forks" -logToSummary $true
              SaveStatus -existingForks $mergedStatus
          } else {
              Write-Message -message "No partial status files found to merge" -logToSummary $true
          }

          # Merge failed forks
          $failedForksFiles = Get-ChildItem -Path "partial-failed" -Filter "failedForks-partial-*.json" -ErrorAction SilentlyContinue | Select-Object -ExpandProperty FullName
          
          if ($failedForksFiles) {
              Write-Message -message "" -logToSummary $true
              Write-Message -message "Found [$(DisplayIntWithDots $failedForksFiles.Count)] partial failed forks files to merge" -logToSummary $true
              
              # Load current failed forks
              $allFailedForks = @()
              if (Test-Path "failedForks.json") {
                  try {
                      $failedContent = Get-Content "failedForks.json" -Raw
                      $failedContent = $failedContent -replace '^\uFEFF', ''
                      $allFailedForks = $failedContent | ConvertFrom-Json
                  } catch {
                      Write-Warning "Failed to parse existing failedForks.json: $($_.Exception.Message)"
                      $allFailedForks = @()
                  }
              }
              
              # Merge partial failed forks
              foreach ($file in $failedForksFiles) {
                  try {
                      $partialContent = Get-Content $file -Raw
                      $partialContent = $partialContent -replace '^\uFEFF', ''
                      $partialFailed = $partialContent | ConvertFrom-Json
                      if ($partialFailed) {
                          $allFailedForks += $partialFailed
                      }
                  } catch {
                      Write-Warning "Failed to process failed forks file [$file]: $($_.Exception.Message)"
                  }
              }
              
              # Remove duplicates and save
              $uniqueFailedForks = $allFailedForks | Sort-Object -Property name -Unique
              Write-Message -message "Merged failed forks: [$(DisplayIntWithDots $uniqueFailedForks.Count)] unique entries" -logToSummary $true
              SaveStatus -failedForks $uniqueFailedForks
          }

          Write-Message -message "" -logToSummary $true
          Write-Message -message "‚úì Consolidation complete" -logToSummary $true

      - name: Show job durations
        shell: pwsh
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          . ./.github/workflows/library.ps1

          Write-Message -message "" -logToSummary $true
          Write-Message -message "## Job Duration Summary" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          # Get job information for current workflow run
          $runId = "${{ github.run_id }}"
          $repo = "${{ github.repository }}"
          
          try {
              # Fetch jobs for this workflow run
              $jobsUrl = "repos/$repo/actions/runs/$runId/jobs?per_page=100"
              $jobs = ApiCall -method "GET" -url $jobsUrl -access_token $env:GH_TOKEN
              
              if ($null -eq $jobs -or $null -eq $jobs.jobs) {
                  Write-Host "No job information available"
                  return
              }
              
              # Filter for fork-repos and repo-info jobs
              $forkJobs = $jobs.jobs | Where-Object { $_.name -like "Fork repos (chunk*" } | Sort-Object { 
                  if ($_.name -match 'chunk (\d+)') { [int]$matches[1] } else { 0 }
              }
              $repoInfoJobs = $jobs.jobs | Where-Object { $_.name -like "Get repo info (chunk*" } | Sort-Object { 
                  if ($_.name -match 'chunk (\d+)') { [int]$matches[1] } else { 0 }
              }
              
              # Display fork-repos jobs
              if ($forkJobs.Count -gt 0) {
                  Write-Message -message "### Fork Repos Jobs" -logToSummary $true
                  Write-Message -message "" -logToSummary $true
                  Write-Message -message "| Chunk | Status | Duration |" -logToSummary $true
                  Write-Message -message "|-------|--------|----------|" -logToSummary $true
                  
                  foreach ($job in $forkJobs) {
                      $chunkId = if ($job.name -match 'chunk (\d+)') { $matches[1] } else { "?" }
                      $status = $job.conclusion
                      if ([string]::IsNullOrEmpty($status)) {
                          $status = $job.status
                      }
                      
                      # Calculate duration
                      $duration = "N/A"
                      if ($null -ne $job.started_at -and $null -ne $job.completed_at) {
                          $startTime = [DateTime]::Parse($job.started_at)
                          $endTime = [DateTime]::Parse($job.completed_at)
                          $durationSpan = $endTime - $startTime
                          
                          $minutes = [math]::Floor($durationSpan.TotalMinutes)
                          $seconds = $durationSpan.Seconds
                          $duration = "$($minutes)m $($seconds)s"
                      }
                      
                      Write-Message -message "| $chunkId | $status | $duration |" -logToSummary $true
                  }
                  
                  Write-Message -message "" -logToSummary $true
              }
              
              # Display repo-info jobs
              if ($repoInfoJobs.Count -gt 0) {
                  Write-Message -message "### Repo Info Jobs" -logToSummary $true
                  Write-Message -message "" -logToSummary $true
                  Write-Message -message "| Chunk | Status | Duration |" -logToSummary $true
                  Write-Message -message "|-------|--------|----------|" -logToSummary $true
                  
                  foreach ($job in $repoInfoJobs) {
                      $chunkId = if ($job.name -match 'chunk (\d+)') { $matches[1] } else { "?" }
                      $status = $job.conclusion
                      if ([string]::IsNullOrEmpty($status)) {
                          $status = $job.status
                      }
                      
                      # Calculate duration
                      $duration = "N/A"
                      if ($null -ne $job.started_at -and $null -ne $job.completed_at) {
                          $startTime = [DateTime]::Parse($job.started_at)
                          $endTime = [DateTime]::Parse($job.completed_at)
                          $durationSpan = $endTime - $startTime
                          
                          $minutes = [math]::Floor($durationSpan.TotalMinutes)
                          $seconds = $durationSpan.Seconds
                          $duration = "$($minutes)m $($seconds)s"
                      }
                      
                      Write-Message -message "| $chunkId | $status | $duration |" -logToSummary $true
                  }
                  
                  Write-Message -message "" -logToSummary $true
              }
              
              Write-Message -message "‚úì Job duration summary complete" -logToSummary $true
          }
          catch {
              Write-Host "Failed to fetch job information: $($_.Exception.Message)"
              Write-Message -message "‚ö†Ô∏è Unable to retrieve job duration information" -logToSummary $true
          }

      - name: Show overall statistics
        shell: pwsh
        run: |
          . ./.github/workflows/library.ps1

          # Load the merged status
          $jsonContent = Get-Content status.json -Raw
          $jsonContent = $jsonContent -replace '^\uFEFF', ''
          $existingForks = $jsonContent | ConvertFrom-Json

          ShowOverallDatasetStatistics -existingForks $existingForks

      - name: Show secret scanning summary
        shell: pwsh
        env:
          APPLICATION_PRIVATE_KEY: ${{ secrets.AUTOMATION_APP_KEY }}
          APPLICATION_PRIVATE_KEY_2: ${{ secrets.AUTOMATION_APP_KEY2 }}
          APPLICATION_PRIVATE_KEY_3: ${{ secrets.AUTOMATION_APP_KEY3 }}
        run: |
          . ./.github/workflows/library.ps1

          Write-Message -message "" -logToSummary $true

          GetFoundSecretCount

      - name: Check rate limit status
        shell: pwsh
        env:
          APPLICATION_PRIVATE_KEY: ${{ secrets.AUTOMATION_APP_KEY }}
          APPLICATION_PRIVATE_KEY_2: ${{ secrets.AUTOMATION_APP_KEY2 }}
          APPLICATION_PRIVATE_KEY_3: ${{ secrets.AUTOMATION_APP_KEY3 }}
        run: |
          . ./.github/workflows/library.ps1

          Invoke-GitHubAppRateLimitCheckForConfiguredApps

      - name: Setup Node.js for API updates
        uses: actions/setup-node@v6
        with:
          node-version: '20'
          registry-url: 'https://npm.pkg.github.com'
          scope: '@devops-actions'

      - name: Install npm package for API updates
        env:
          NODE_AUTH_TOKEN: ${{ secrets.DEVOPS_ACTIONS_PACKAGE_DOWNLOAD }}
        run: |
          npm install @devops-actions/actions-marketplace-client

      - name: Update API storage with consolidated data
        if: always()
        shell: pwsh
        env:
          AZ_FUNCTION_URL: ${{ vars.AZ_FUNCTION_URL }}
          AZ_FUNCTION_TOKEN: ${{ secrets.AZ_FUNCTION_TOKEN }}
        run: |
          . ./.github/workflows/library.ps1

          Write-Message -message "" -logToSummary $true
          Write-Message -message "## API Storage Update" -logToSummary $true
          Write-Message -message "" -logToSummary $true

          # Check if API credentials are available
          if ([string]::IsNullOrWhiteSpace($env:AZ_FUNCTION_URL) -or [string]::IsNullOrWhiteSpace($env:AZ_FUNCTION_TOKEN)) {
            Write-Message -message "‚ö†Ô∏è API credentials not available - skipping API update" -logToSummary $true
            exit 0
          }

          # Load the merged status
          try {
            $jsonContent = Get-Content status.json -Raw
            $jsonContent = $jsonContent -replace '^\uFEFF', ''
            $status = $jsonContent | ConvertFrom-Json
          } catch {
            Write-Message -message "‚ùå Failed to load status.json: $($_.Exception.Message)" -logToSummary $true
            exit 0
          }

          Write-Host "Uploading up to 100 actions to API storage..."

          # Call the API upsert function
          $numberOfRepos = 100
          $result = Invoke-ApiUpsert -status $status -apiUrl $env:AZ_FUNCTION_URL -functionKey $env:AZ_FUNCTION_TOKEN -numberOfRepos $numberOfRepos

          # Report results in step summary
          if ($result.error) {
            Write-Message -message "‚ö†Ô∏è API update encountered an error: $($result.error)" -logToSummary $true
          } else {
            $totalUpdates = $result.createdCount + $result.updatedCount
            Write-Message -message "| Status | Count |" -logToSummary $true
            Write-Message -message "|--------|------:|" -logToSummary $true
            Write-Message -message "| ‚úÖ Successful | $($result.successCount) |" -logToSummary $true
            Write-Message -message "| ‚ùå Failed | $($result.failCount) |" -logToSummary $true
            Write-Message -message "| üÜï Created | $($result.createdCount) |" -logToSummary $true
            Write-Message -message "| üìù Updated | $($result.updatedCount) |" -logToSummary $true
            Write-Message -message "| ‚è≠Ô∏è Skipped | $($result.skippedCount) |" -logToSummary $true
            Write-Message -message "" -logToSummary $true
            Write-Message -message "‚úì Total updates to API: **$totalUpdates** (created + updated)" -logToSummary $true
          }

          Write-Message -message "" -logToSummary $true

      - name: Upload status.json to blob storage
        if: always()
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Set-StatusToBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Warning "Failed to upload status.json to blob storage"
            # Don't exit 1 here - we want to continue to upload failedForks.json
          } else {
            Write-Host "Successfully uploaded status.json to blob storage"
          }

      - name: Upload failedForks.json to blob storage
        if: always()
        shell: pwsh
        env:
          BLOB_SAS_TOKEN: "${{ secrets.BLOB_SAS_TOKEN }}"
        run: |
          . ./.github/workflows/library.ps1
          $result = Set-FailedForksToBlobStorage -sasToken $env:BLOB_SAS_TOKEN
          if (-not $result) {
            Write-Warning "Failed to upload failedForks.json to blob storage"
            # Don't exit 1 here - we still want the workflow to complete
          } else {
            Write-Host "Successfully uploaded failedForks.json to blob storage"
          }
